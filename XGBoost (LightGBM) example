import pandas as pd
df = pd.read_csv("C:/.../MEW FiberDiameter 21_4.csv")
df.head()

df = df.drop(labels=['id','nuzsize','pritemp','diameter','CUR'],axis=1)
df.head()

Y = df.curved
X = df.drop(labels=['curved'],axis=1)
X.head()

import sklearn
from sklearn.model_selection import train_test_split
import numpy as np
import shap
import time

X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size=0.2, random_state=0)

def print_accuracy(f):
    print("Accuracy = {0}%".format(100*np.sum(f(X_test) == Y_test)/len(Y_test)))
    time.sleep(0.5) # to let the print get out before any progress bars

shap.initjs()

knn = sklearn.neighbors.KNeighborsClassifier()
knn.fit(X_train, Y_train)

print_accuracy(knn.predict)


shap_values = shap.KernelExplainer(knn.predict_proba, X_train).shap_values(X_test.iloc[0,:])
shap.force_plot(shap_values[0], X_test.iloc[0,:])

shap_values = shap.KernelExplainer(knn.predict_proba, X_train).shap_values(X_test)
shap.force_plot(shap_values[0], X_test)

svc_linear = sklearn.svm.SVC(kernel='linear', probability=True)
svc_linear.fit(X_train, Y_train)
print_accuracy(svc_linear.predict)

# explain all the predictions in the test set
shap_values = shap.KernelExplainer(svc_linear.predict_proba, X_train).shap_values(X_test)
shap.force_plot(shap_values[0], X_test)

svc_linear = sklearn.svm.SVC(kernel='rbf', probability=True)
svc_linear.fit(X_train, Y_train)
print_accuracy(svc_linear.predict)

# explain all the predictions in the test set
shap_values = shap.KernelExplainer(svc_linear.predict_proba, X_train).shap_values(X_test)
shap.force_plot(shap_values[0], X_test)

linear_lr = sklearn.linear_model.LogisticRegression()
linear_lr.fit(X_train, Y_train)
print_accuracy(linear_lr.predict)

# explain all the predictions in the test set
shap_values = shap.KernelExplainer(linear_lr.predict_proba, X_train).shap_values(X_test)
shap.force_plot(shap_values[0], X_test)

import sklearn.tree 
dtree = sklearn.tree.DecisionTreeClassifier(min_samples_split=2)
dtree.fit(X_train, Y_train)
print_accuracy(dtree.predict)

# explain all the predictions in the test set
shap_values = shap.KernelExplainer(dtree.predict_proba, X_train).shap_values(X_test)
shap.force_plot(shap_values[0], X_test)

from sklearn.ensemble import RandomForestClassifier
rforest = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=0)
rforest.fit(X_train, Y_train)
print_accuracy(rforest.predict)

# explain all the predictions in the test set
shap_values = shap.KernelExplainer(rforest.predict_proba, X_train).shap_values(X_test)
shap.force_plot(shap_values[0], X_test)

from sklearn.neural_network import MLPClassifier
nn = MLPClassifier(solver='lbfgs', alpha=1e-1, hidden_layer_sizes=(5, 2), random_state=0)
nn.fit(X_train, Y_train)
print_accuracy(nn.predict)

# explain all the predictions in the test set
shap_values = shap.KernelExplainer(nn.predict_proba, X_train).shap_values(X_test)
shap.force_plot(shap_values[0], X_test)
















